[
{
	"uri": "/r_content/lb_01/lb_01.html",
	"title": "LB Facets",
	"tags": ["graph", "ggplot2"],
	"description": "",
	"content": "2021-07-02, FCA Collin\nlibrary(tidyverse) ## ── Attaching packages ─────────────────────────────────────────────────────────────── tidyverse 1.3.0 ── ## ✔ ggplot2 3.3.3 ✔ purrr 0.3.4 ## ✔ tibble 3.1.1 ✔ dplyr 1.0.5 ## ✔ tidyr 1.1.3 ✔ stringr 1.4.0 ## ✔ readr 1.4.0 ✔ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag()  # Simulated adlb adlb \u0026lt;- expand.grid( USUBJID = paste(\u0026#34;subj\u0026#34;, 1:50), AVISITN = 0:10, ARMCD = paste(\u0026#34;Arm\u0026#34;, c(\u0026#34;A\u0026#34;, \u0026#34;B\u0026#34;)), PARAMCD = \u0026#34;prm 1\u0026#34; ) adlb$AVISIT \u0026lt;- paste(\u0026#34;VST\u0026#34;, adlb$AVISIT) adlb \u0026lt;- do.call( rbind, lapply( X = split(adlb, f = adlb$AVISITN), FUN = function(x) { x$AVAL \u0026lt;- rbeta(nrow(x), (unique(x$AVISITN) + 2)*0.5, 4) + 1 x }) ) adlb \u0026lt;- rbind( adlb, within(adlb, {PARAMCD = \u0026#34;prm 2\u0026#34;; AVAL = 0.2 * AVAL}), within(adlb, {PARAMCD = \u0026#34;prm 3\u0026#34;; AVAL = 0.5 * AVAL}), within(adlb, {PARAMCD = \u0026#34;prm 4\u0026#34;; AVAL = 0.8 * AVAL}) ) Proposed preprocessing ## Identify Max visit if not already done in ADLB lb_max \u0026lt;- adlb %\u0026gt;% group_by(USUBJID, PARAMCD, ARMCD) %\u0026gt;% slice(which.max(AVAL)) %\u0026gt;% mutate(AVISIT = \u0026#34;MAX\u0026#34;) %\u0026gt;% ungroup() ## Identify Baseline visit if not already done in ADLB lb_bl \u0026lt;- adlb %\u0026gt;% group_by(USUBJID, ARMCD) %\u0026gt;% filter(AVISITN == 0) %\u0026gt;% # Change if Baseline differently identifed e.g. ABLFL mutate(AVISIT = \u0026#34;BL\u0026#34;) %\u0026gt;% ungroup() ## Combine baseline and max in Analysis DataSet [ads] ads \u0026lt;- bind_rows(lb_max, lb_bl) Graph ## Simple ads_plot \u0026lt;- pivot_wider(ads, names_from = AVISIT, values_from = AVAL, -AVISITN) gg \u0026lt;- ggplot(data = ads_plot, mapping = aes(x = BL, y = MAX, color = ARMCD)) + geom_point() + geom_abline(intercept = 0, slope = 1) + geom_hline(yintercept = 1:2, lty = 2) + geom_vline(xintercept = 1:2, lty = 2) + facet_wrap(. ~ PARAMCD) + ggtitle(\u0026#34;Panel of PRMs from Baseline to Maximum by Treatment\u0026#34;) + xlab(\u0026#34;Baseline (/ULN)\u0026#34;) + ylab(\u0026#34;Maximum (/ULN)\u0026#34;) + theme_minimal() + theme(asp = 1) gg ## Independent scales in facets ### Identify Min / Max values in ads to keep asp = 1 ads_lim \u0026lt;- split(ads, f = ads[c(\u0026#34;ARMCD\u0026#34;, \u0026#34;PARAMCD\u0026#34;)]) ads_lim \u0026lt;- lapply( X = ads_lim, FUN = function(x) { df \u0026lt;- unique(x[c(\u0026#34;ARMCD\u0026#34;, \u0026#34;PARAMCD\u0026#34;)]) row.names(df) \u0026lt;- NULL cbind( df, AVISIT = unname(rep(unique(x$AVISIT), 2)), range = rep(c(\u0026#34;min\u0026#34;, \u0026#34;max\u0026#34;), each = 2) , AVAL = rep(range(x$AVAL), each = 2) ) } ) ads_lim \u0026lt;- do.call(bind_rows, ads_lim) %\u0026gt;% pivot_wider(names_from = AVISIT, values_from = AVAL) ### Update figure gg \u0026lt;- ggplot(data = ads_lim, mapping = aes(x = BL, y = MAX, color = ARMCD)) + geom_blank() + geom_point(data = ads_plot, mapping = aes(x = BL, y = MAX, color = ARMCD)) + geom_abline(intercept = 0, slope = 1) + geom_hline(yintercept = 1:2, lty = 2) + geom_vline(xintercept = 1:2, lty = 2) + facet_wrap(. ~ PARAMCD, scales = \u0026#34;free\u0026#34;) + ggtitle(\u0026#34;Panel of PRMs from Baseline to Maximum by Treatment\u0026#34;) + xlab(\u0026#34;Baseline (/ULN)\u0026#34;) + ylab(\u0026#34;Maximum (/ULN)\u0026#34;) + theme_minimal() + theme(asp = 1) gg sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.5 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.3 tibble_3.1.1 ggplot2_3.3.3 ## [9] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.1 xfun_0.22 haven_2.4.1 colorspace_2.0-1 ## [5] vctrs_0.3.8 generics_0.1.0 htmltools_0.5.1.1 yaml_2.2.1 ## [9] utf8_1.2.1 rlang_0.4.11 pillar_1.6.0 withr_2.4.1 ## [13] glue_1.4.2 DBI_1.1.1 dbplyr_2.0.0 modelr_0.1.8 ## [17] readxl_1.3.1 lifecycle_1.0.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_1.0.0 evaluate_0.14 labeling_0.4.2 ## [25] knitr_1.33 ps_1.6.0 fansi_0.4.2 highr_0.9 ## [29] broom_0.7.6 Rcpp_1.0.6 scales_1.1.1 backports_1.2.1 ## [33] jsonlite_1.7.2 farver_2.1.0 fs_1.5.0 hms_1.0.0 ## [37] digest_0.6.27 stringi_1.5.3 grid_4.0.4 cli_2.5.0 ## [41] tools_4.0.4 magrittr_2.0.1 crayon_1.4.1 pkgconfig_2.0.3 ## [45] ellipsis_0.3.2 xml2_1.3.2 reprex_1.0.0 lubridate_1.7.10 ## [49] assertthat_0.2.1 rmarkdown_2.6 httr_1.4.2 rstudioapi_0.13 ## [53] R6_2.5.0 compiler_4.0.4 "
},
{
	"uri": "/r_content/btc/btc_02/btc_02.html",
	"title": "A Bit of Style",
	"tags": [],
	"description": "",
	"content": "2021-03-11, FCA Collin\nStyle Advises Use Comment Appropriately Main reason to comment:\n Code Readability Explanation of the code or Metadata of the project Temporarily prevent execution of code To include resources  https://style.tidyverse.org/syntax.html (210415):\nIn data analysis code, use comments to record important findings and analysis decisions. If you need comments to explain what your code is doing, consider rewriting your code to be clearer. If you discover that you have more comments than code, consider switching to R Markdown.\nHow to comment https://style.tidyverse.org/functions.html (210415):\n Explain the why and not the what or how Comments should be in sentence case, and only end with a full stop if they contain at least two sentences  Down-side of (bad) comment practice.  Focus and cognitive load: stops screening code because maybe that is important (and 99% of case is not). Hides what’s important: increase the length of the code. If, eventually, it is understood by the programmer who commented it, it is noise to every one else. It is better to keep the code to the necessary piece and as, along with other measures, it will improve code maintenance by preventing to have to look for the needle in the haystack.  Alternative: if all this comment is necessary, use literate programming such as rmarkdown.  The commented code does not evolve and may become out of date: and this is a problem as all the code should work. Unfinished job: the comment can be an alternative code as the programmer thinks “*maybe that could be another valid approach*”. The programmer is still the better placed to decided what is better, or may ask advises, but the job will be finish when finally ruling the decision. Alternative:  if it is hard to decide, take the time to weight the decision, eventually ask another colleague. if the decision must be documented: consider literate programming with rmarkdown.  Someone else will delete it. As ambiguous, someone may decide to delete the commented code. If this was really informative, that will be a loss which could have been prevented (i.e. literate programming, unit tests). Some programmers think:  I’ll Delete Your Commented Code Without Reading It and I’m Not Sorry https://blog.submain.com/delete-commented-code-without-reading/   Around the Web:\n https://kentcdodds.com/blog/please-dont-commit-commented-out-code https://agiletribe.wordpress.com/2015/12/26/never-leave-commented-code-in-the-source/ https://blog.submain.com/delete-commented-code-without-reading/  Few quotes:\n The cost of that commented code always outweighs the benefit. Deleting commented code is an easy and effective way to improve the code base, without any risk of negative consequences.  sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.4 magrittr_2.0.1 tools_4.0.4 htmltools_0.5.1.1 ## [5] yaml_2.2.1 stringi_1.5.3 rmarkdown_2.6 knitr_1.31 ## [9] stringr_1.4.0 xfun_0.22 digest_0.6.27 rlang_0.4.10 ## [13] evaluate_0.14 "
},
{
	"uri": "/r_content/btc/btc_01/btc_01.html",
	"title": "Beat The Code",
	"tags": [],
	"description": "",
	"content": "2021-03-11, FCA Collin\nTidyverse, Not a Golden Hammer The Law of the instrument describes a cognitive bias:\n “I call it the law of the instrument, and it may be formulated as follows: Give a small boy a hammer, and he will find that everything he encounters needs pounding.” (Abraham Kaplan, 1964)\n It was identified as an AntiPattern, a programming practice to be avoided (William Brown et al, 1998). One of the pit fall is expressed as:\n “the tendency of jobs to be adapted to tools, rather than adapting tools to jobs” (Silvan Tomkins, 1963).\n The tidyverse package helps end-user in R-coding delimited statistic tasks. It is a very good idea to use it if your purpose is to walk through an analysis from a point A (the dataset) to the point B (the result) for procedures of limited complexity. Indeed, with a limited number of human-readable functions you can get the expected result while helping the future reader to follow the procedure. However, as soon as you want to resolve statistical problems in a more systemic way, by creating functions that will help you to get your result in a more concise (because accurate) code and tested for and documented and robust, tidyverse is not the most suitable choice.\nThe package vignette itself enclose a clear disclaimer about the package rational:\n “the biggest difference is in priorities: base R is highly focussed on stability, whereas the tidyverse will make breaking changes in the search for better interfaces.” Welcome to the Tidyverse vignette, 2019\n The trade-off between stability and interface evolution is also acknowledged:\n Do you expect the tidyverse to be the part of core R packages some day?\nHadley Wickham: “It’s extremely unlikely because the core packages are extremely conservative so that base R code is stable, and backward compatible. I prefer to have a more utopian approach where I can be quite aggressive about making backward incompatible changes while trying to figure out a better API.” quora\n There is no doubt that tidyverse is a set of high quality tools, but it is designed to serve some purpose: easy and highly readable code at the cost of stability which is a strategy which can’t serve all developments. Besides, the over reliance of craftsperson on a known tool, brings to see the challenge not as it is but how it fit to the tool. As a matter of fact, an over reliance on tidyverse risk to introduce a cognitive bias, increasing the risk of of deviation from initial target as fitting your purpose to the problem instead of making the method suitable to answer specific question. The over-reliance can be evidence by a large tidyverse block which have obviously lost the main sells argument of the package: readability.\nIn order to increase the range of possible ways to address a question, so as to minimise the risk of programming cognitive bias, it is good to demonstrate alternatives to the tidyverse approach put in some context, and present the R base alternative. There will be a trade-off switching from one to the other about readability, performance and code stability. But, maybe, this will also help thinking about different approaches to address statistical problems.\nFilter and Select library(tidyverse) Tidyerse Non-Standard Evaluation:\niris %\u0026gt;% filter(Species == \u0026#34;setosa\u0026#34;) %\u0026gt;% select(Sepal.Width, Sepal.Length) %\u0026gt;% head ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base Non-Standard Evaluation:\nsel \u0026lt;- subset( iris, subset = Species == \u0026#34;setosa\u0026#34;, select = c(Sepal.Width, Sepal.Length) ) head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base data.frame accessors:\nsel \u0026lt;- iris[ iris$Species == \u0026#34;setosa\u0026#34;, c(\u0026#34;Sepal.Width\u0026#34;, \u0026#34;Sepal.Length\u0026#34;) ] head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Mutate df[df$age \u0026gt; 90, ] \u0026lt;- NAsessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.5 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.3 tibble_3.1.0 ggplot2_3.3.3 ## [9] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.0 xfun_0.22 haven_2.3.1 colorspace_2.0-0 ## [5] vctrs_0.3.7 generics_0.1.0 htmltools_0.5.1.1 yaml_2.2.1 ## [9] utf8_1.2.1 rlang_0.4.10 pillar_1.5.1 withr_2.4.1 ## [13] glue_1.4.2 DBI_1.1.1 dbplyr_2.0.0 modelr_0.1.8 ## [17] readxl_1.3.1 lifecycle_1.0.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_1.0.0 evaluate_0.14 knitr_1.31 ## [25] ps_1.6.0 fansi_0.4.2 broom_0.7.5 Rcpp_1.0.6 ## [29] scales_1.1.1 backports_1.2.1 jsonlite_1.7.2 fs_1.5.0 ## [33] hms_1.0.0 digest_0.6.27 stringi_1.5.3 grid_4.0.4 ## [37] cli_2.3.1 tools_4.0.4 magrittr_2.0.1 crayon_1.4.1 ## [41] pkgconfig_2.0.3 ellipsis_0.3.1 xml2_1.3.2 reprex_1.0.0 ## [45] lubridate_1.7.10 assertthat_0.2.1 rmarkdown_2.6 httr_1.4.2 ## [49] rstudioapi_0.13 R6_2.5.0 compiler_4.0.4 "
},
{
	"uri": "/r_content/utils_01/btc_01.html",
	"title": "Beat The Code",
	"tags": [],
	"description": "",
	"content": "2021-03-11, FCA Collin\nTidyverse, Not a Golden Hammer The Law of the instrument describes a cognitive bias:\n “I call it the law of the instrument, and it may be formulated as follows: Give a small boy a hammer, and he will find that everything he encounters needs pounding.” (Abraham Kaplan, 1964)\n It was identified as an AntiPattern, a programming practice to be avoided (William Brown et al, 1998). One of the pit fall is expressed as:\n “the tendency of jobs to be adapted to tools, rather than adapting tools to jobs” (Silvan Tomkins, 1963).\n The tidyverse package helps end-user in R-coding delimited statistic tasks. It is a very good idea to use it if your purpose is to walk through an analysis from a point A (the dataset) to the point B (the result) for procedures of limited complexity. Indeed, with a limited number of human-readable functions you can get the expected result while helping the future reader to follow the procedure. However, as soon as you want to resolve statistical problems in a more systemic way, by creating functions that will help you to get your result in a more concise (because accurate) code and tested for and documented and robust, tidyverse is not the most suitable choice.\nThe package vignette itself enclose a clear disclaimer about the package rational:\n “the biggest difference is in priorities: base R is highly focussed on stability, whereas the tidyverse will make breaking changes in the search for better interfaces.” Welcome to the Tidyverse vignette, 2019\n The trade-off between stability and interface evolution is also acknowledged:\n Do you expect the tidyverse to be the part of core R packages some day?\nHadley Wickham: “It’s extremely unlikely because the core packages are extremely conservative so that base R code is stable, and backward compatible. I prefer to have a more utopian approach where I can be quite aggressive about making backward incompatible changes while trying to figure out a better API.” quora\n There is no doubt that tidyverse is a set of high quality tools, but it is designed to serve some purpose: easy and highly readable code at the cost of stability which is a strategy which can’t serve all developments. Besides, the over reliance of craftsperson on a known tool, brings to see the challenge not as it is but how it fit to the tool. As a matter of fact, an over reliance on tidyverse risk to introduce a cognitive bias, increasing the risk of of deviation from initial target as fitting your purpose to the problem instead of making the method suitable to answer specific question. The over-reliance can be evidence by a large tidyverse block which have obviously lost the main sells argument of the package: readability.\nIn order to increase the range of possible ways to address a question, so as to minimise the risk of programming cognitive bias, it is good to demonstrate alternatives to the tidyverse approach put in some context, and present the R base alternative. There will be a trade-off switching from one to the other about readability, performance and code stability. But, maybe, this will also help thinking about different approaches to address statistical problems.\nFilter and Select library(tidyverse)  Tidyerse Non-Standard Evaluation:\niris %\u0026gt;% filter(Species == \u0026quot;setosa\u0026quot;) %\u0026gt;% select(Sepal.Width, Sepal.Length) %\u0026gt;% head ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base Non-Standard Evaluation:\nsel \u0026lt;- subset( iris, subset = Species == \u0026quot;setosa\u0026quot;, select = c(Sepal.Width, Sepal.Length) ) head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Base data.frame accessors:\nsel \u0026lt;- iris[ iris$Species == \u0026quot;setosa\u0026quot;, c(\u0026quot;Sepal.Width\u0026quot;, \u0026quot;Sepal.Length\u0026quot;) ] head(sel) ## Sepal.Width Sepal.Length ## 1 3.5 5.1 ## 2 3.0 4.9 ## 3 3.2 4.7 ## 4 3.1 4.6 ## 5 3.6 5.0 ## 6 3.9 5.4  Mutate df[df$age \u0026gt; 90, ] \u0026lt;- NA sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.5 purrr_0.3.4 ## [5] readr_1.4.0 tidyr_1.1.3 tibble_3.1.0 ggplot2_3.3.3 ## [9] tidyverse_1.3.0 ## ## loaded via a namespace (and not attached): ## [1] tidyselect_1.1.0 xfun_0.22 haven_2.3.1 colorspace_2.0-0 ## [5] vctrs_0.3.6 generics_0.1.0 htmltools_0.5.1.1 yaml_2.2.1 ## [9] utf8_1.2.1 rlang_0.4.10 pillar_1.5.1 withr_2.4.1 ## [13] glue_1.4.2 DBI_1.1.1 dbplyr_2.0.0 modelr_0.1.8 ## [17] readxl_1.3.1 lifecycle_1.0.0 munsell_0.5.0 gtable_0.3.0 ## [21] cellranger_1.1.0 rvest_1.0.0 evaluate_0.14 knitr_1.31 ## [25] ps_1.6.0 fansi_0.4.2 broom_0.7.5 Rcpp_1.0.6 ## [29] scales_1.1.1 backports_1.2.1 jsonlite_1.7.2 fs_1.5.0 ## [33] hms_1.0.0 digest_0.6.27 stringi_1.5.3 grid_4.0.4 ## [37] cli_2.3.1 tools_4.0.4 magrittr_2.0.1 crayon_1.4.1 ## [41] pkgconfig_2.0.3 ellipsis_0.3.1 xml2_1.3.2 reprex_1.0.0 ## [45] lubridate_1.7.10 assertthat_0.2.1 rmarkdown_2.6 httr_1.4.2 ## [49] rstudioapi_0.13 R6_2.5.0 compiler_4.0.4 "
},
{
	"uri": "/r_content/utils/palette_swatch_01/palette_swatch_01.html",
	"title": "Palette Swatch",
	"tags": [],
	"description": "",
	"content": "2021-03-19, FCA Collin\nGood toy example to practice grid viewport and grob trees.\nUse Cases palette_swatch(viridis::viridis_pal(option = \u0026#34;A\u0026#34;)(20)) palette_swatch(viridis::viridis_pal(option = \u0026#34;B\u0026#34;)(10)) palette_swatch(viridis::viridis_pal(option = \u0026#34;C\u0026#34;)(5)) palette_swatch(viridis::viridis_pal(option = \u0026#34;D\u0026#34;)(20)) palette_swatch(viridis::viridis_pal(option = \u0026#34;E\u0026#34;)(20)) palette_swatch(viridis::viridis_pal(option = \u0026#34;F\u0026#34;)(10)) palette_swatch(viridis::viridis_pal(option = \u0026#34;G\u0026#34;)(5)) palette_swatch(viridis::viridis_pal(option = \u0026#34;H\u0026#34;)(20)) Definition #\u0026#39; Palette Swatch #\u0026#39; #\u0026#39; Represent a color palette. #\u0026#39; #\u0026#39; @param ... (`atomic`)\\cr valid color(s) (according to grid) #\u0026#39; @param draw (`logical`) #\u0026#39; @export #\u0026#39; @examples #\u0026#39; #\u0026#39; palette_swatch(\u0026#34;gray\u0026#34;, \u0026#34;red\u0026#34;, \u0026#34;gray\u0026#34;, NA, \u0026#34;blue\u0026#34;) #\u0026#39; palette_swatch \u0026lt;- function(..., draw = TRUE) { colors \u0026lt;- list(...) lapply(colors, function(x) assertthat::assert_that(is.atomic(x))) colors \u0026lt;- unlist(colors) nm \u0026lt;- paste(colors, seq_along(colors), sep = \u0026#34;_\u0026#34;) vp \u0026lt;- grid::vpTree( parent = grid::viewport(name = \u0026#34;page\u0026#34;, width = 0.95, height = 0.95), children = do.call( grid::vpList, Map( nm = nm, x = seq_along(colors) / (length(colors)), width = 1 / length(colors), f = function(nm, x, width) { grid::viewport( name = nm, x = x, width = width, just = \u0026#34;right\u0026#34; ) } ) ) ) gr \u0026lt;- do.call( grid::gList, Map( colors, nm, f = function(colors, nm) { grid::gTree( vp = nm, children = grid::gList( grid::rectGrob(gp = grid::gpar(fill = colors, col = colors)) ) ) } ) ) gr \u0026lt;- grid::gTree( childrenvp = vp, children = grid::gList( grid::gTree( vp = \u0026#34;page\u0026#34;, children = gr ) ) ) if (draw) { grid::grid.newpage() grid::grid.draw(gr) } else { invisible() } } Unit tests library(testthat) test_that(\u0026#34;palette_swatch works if atomic\u0026#34;, { expect_silent(palette_swatch(\u0026#34;gray\u0026#34;, draw = FALSE)) expect_silent(palette_swatch(\u0026#34;gray\u0026#34;, c(\u0026#34;blue\u0026#34;, \u0026#34;green\u0026#34;), draw = FALSE)) expect_silent(palette_swatch(\u0026#34;gray\u0026#34;, \u0026#34;red\u0026#34;, NA, \u0026#34;blue\u0026#34;, draw = FALSE)) }) ## Test passed 🥇  test_that(\u0026#34;palette_swatch works if a color is repeated\u0026#34;, { expect_silent(palette_swatch(rep(\u0026#34;gray\u0026#34;, 10), draw = FALSE)) expect_silent(palette_swatch(\u0026#34;red\u0026#34;, \u0026#34;red\u0026#34;, draw = FALSE)) }) ## Test passed 😸  test_that(\u0026#34;palette_swatch fail if non-atomic\u0026#34;, { expect_error(palette_swatch(\u0026#34;gray\u0026#34;, iris, draw = FALSE)) }) ## Test passed 🌈  sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] testthat_3.0.2 ## ## loaded via a namespace (and not attached): ## [1] pillar_1.6.0 compiler_4.0.4 highr_0.9 viridis_0.6.0 ## [5] tools_4.0.4 pkgload_1.1.0 digest_0.6.27 evaluate_0.14 ## [9] lifecycle_1.0.0 tibble_3.1.1 gtable_0.3.0 viridisLite_0.4.0 ## [13] pkgconfig_2.0.3 rlang_0.4.11 rstudioapi_0.13 cli_2.5.0 ## [17] DBI_1.1.1 yaml_2.2.1 xfun_0.22 gridExtra_2.3 ## [21] withr_2.4.1 stringr_1.4.0 dplyr_1.0.5 knitr_1.33 ## [25] desc_1.3.0 generics_0.1.0 vctrs_0.3.8 rprojroot_2.0.2 ## [29] grid_4.0.4 tidyselect_1.1.1 glue_1.4.2 R6_2.5.0 ## [33] fansi_0.4.2 rmarkdown_2.6 ggplot2_3.3.3 purrr_0.3.4 ## [37] magrittr_2.0.1 ps_1.6.0 scales_1.1.1 ellipsis_0.3.2 ## [41] htmltools_0.5.1.1 assertthat_0.2.1 colorspace_2.0-1 utf8_1.2.1 ## [45] stringi_1.5.3 munsell_0.5.0 crayon_1.4.1 "
},
{
	"uri": "/r_content/utils_01/utils_01.html",
	"title": "Utils",
	"tags": [],
	"description": "",
	"content": "2021-03-19, FCA Collin\nDummy var #\u0026#39; Dummy Variable #\u0026#39; #\u0026#39; Decompose a factor-coercible variable into dummy variables. #\u0026#39;  #\u0026#39; @param x (`atomic`) #\u0026#39; @export #\u0026#39; @source \u0026lt;https://fcacollin.github.io/guide/utils_01/utils_01.html\u0026gt; #\u0026#39; @md #\u0026#39; @examples #\u0026#39; # Use case data.frame. #\u0026#39; head(iris) #\u0026#39; head(dummy_var(iris$Species)) #\u0026#39; iris$sp \u0026lt;- dummy_var(iris$Species) #\u0026#39; head(iris) #\u0026#39;  #\u0026#39; # With logical. #\u0026#39; dummy_var(c(TRUE, FALSE)) #\u0026#39;  #\u0026#39; # With character. #\u0026#39; dummy_var(c(\u0026#34;cat\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;, \u0026#34;corgi\u0026#34;, \u0026#34;corgi\u0026#34;)) #\u0026#39;  dummy_var \u0026lt;- function(x) { stopifnot(is.atomic(x)) if (!is.factor(x)) { x \u0026lt;- as.factor(x) } x \u0026lt;- droplevels(x) y \u0026lt;- stats::model.matrix(~ x + 0) colnames(y) \u0026lt;- levels(x) as.data.frame(y) }# Use case data.frame. head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa  head(dummy_var(iris$Species)) ## setosa versicolor virginica ## 1 1 0 0 ## 2 1 0 0 ## 3 1 0 0 ## 4 1 0 0 ## 5 1 0 0 ## 6 1 0 0  iris$sp \u0026lt;- dummy_var(iris$Species) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species sp.setosa ## 1 5.1 3.5 1.4 0.2 setosa 1 ## 2 4.9 3.0 1.4 0.2 setosa 1 ## 3 4.7 3.2 1.3 0.2 setosa 1 ## 4 4.6 3.1 1.5 0.2 setosa 1 ## 5 5.0 3.6 1.4 0.2 setosa 1 ## 6 5.4 3.9 1.7 0.4 setosa 1 ## sp.versicolor sp.virginica ## 1 0 0 ## 2 0 0 ## 3 0 0 ## 4 0 0 ## 5 0 0 ## 6 0 0  # With logical. dummy_var(c(TRUE, FALSE)) ## FALSE TRUE ## 1 0 1 ## 2 1 0  # With character. dummy_var(c(\u0026#34;cat\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;dog\u0026#34;, \u0026#34;corgi\u0026#34;, \u0026#34;corgi\u0026#34;)) ## cat corgi dog ## 1 1 0 0 ## 2 1 0 0 ## 3 0 0 1 ## 4 0 1 0 ## 5 0 1 0  Matrix To Long Format #\u0026#39; Matrix-like Data To Long Data Frame #\u0026#39; #\u0026#39; Transform a matrix-like data set into a long data frame. #\u0026#39; mat_to_long_df \u0026lt;- function(x, ...) { UseMethod(\u0026#34;mat_to_long_df\u0026#34;, x) } mat_to_long_df.matrix \u0026lt;- function(x, names = c(\u0026#34;row\u0026#34;, \u0026#34;col\u0026#34;, \u0026#34;value\u0026#34;), ...) { assertthat::assert_that(length(names) == 3L) if (is.null(colnames(x))) colnames(x) \u0026lt;- as.character(seq_len(ncol(x))) if (is.null(rownames(x))) rownames(x) \u0026lt;- as.character(seq_len(nrow(x))) y \u0026lt;- data.frame( rownames(x)[c(row(x))], colnames(x)[c(col(x))], c(x), row.names = NULL ) names(y) \u0026lt;- names y } mat_to_long_df.data.frame \u0026lt;- function(x, ...) { x \u0026lt;- as.matrix(x) mat_to_long_df(x, ...) } m \u0026lt;- matrix( c( 11, 12, 21, 22, 31, 32 ), nrow = 3, byrow = TRUE, dimnames = list(row = 1:3, col = 1:2) ) df \u0026lt;- as.data.frame(m) mat_to_long_df(m) ## row col value ## 1 1 1 11 ## 2 2 1 21 ## 3 3 1 31 ## 4 1 2 12 ## 5 2 2 22 ## 6 3 2 32  mat_to_long_df(df) ## row col value ## 1 1 1 11 ## 2 2 1 21 ## 3 3 1 31 ## 4 1 2 12 ## 5 2 2 22 ## 6 3 2 32  library(testthat) test_that(\u0026#34;mat_to_long_df names are used\u0026#34;, { result \u0026lt;- mat_to_long_df(m, names = c(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;y\u0026#34;)) expected \u0026lt;- data.frame( a = c(\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34;), b = c(\u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;2\u0026#34;), y = c(11, 21, 31, 12, 22, 32) ) expect_identical(result, expected) }) ## Test passed 😀  test_that(\u0026#34;mat_to_long_df error if not 3 names provided\u0026#34;, { expect_error(mat_to_long_df(m, names = \u0026#34;a\u0026#34;)) }) ## Test passed 🥇  Set a theme for ggplot2 #\u0026#39; `ggplot` theme #\u0026#39; #\u0026#39; Compliance with journal requirements. #\u0026#39; @param reset (`flag`). #\u0026#39; @export #\u0026#39; theme_rpack \u0026lt;- function(reset = FALSE) { assertthat::assert_that(is.logical(reset)) if (reset) { ggplot2::theme_set(ggplot2::theme_gray()) } else { new_theme \u0026lt;- ggplot2::theme_minimal() + ggplot2::theme( line = ggplot2::element_line(color = \u0026#34;black\u0026#34;), legend.position = \u0026#34;bottom\u0026#34;, legend.key.height = grid::unit(.3, \u0026#34;cm\u0026#34;), text = ggplot2::element_text(size = 8), plot.margin = ggplot2::margin(0, 0, 0, 0, \u0026#34;cm\u0026#34;), legend.margin = ggplot2::margin(0, 0, 0, 0, \u0026#34;cm\u0026#34;) ) ggplot2::theme_set(new_theme) } }library(ggplot2) gg \u0026lt;- ggplot(economics, aes(date, unemploy)) + geom_line() gg theme_rpack() gg theme_rpack(reset = TRUE) gg sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.3 testthat_3.0.2 ## ## loaded via a namespace (and not attached): ## [1] highr_0.9 compiler_4.0.4 pillar_1.6.0 tools_4.0.4 ## [5] digest_0.6.27 pkgload_1.1.0 evaluate_0.14 lifecycle_1.0.0 ## [9] tibble_3.1.1 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.11 ## [13] DBI_1.1.1 cli_2.5.0 rstudioapi_0.13 yaml_2.2.1 ## [17] xfun_0.22 withr_2.4.1 stringr_1.4.0 dplyr_1.0.5 ## [21] knitr_1.33 generics_0.1.0 desc_1.3.0 vctrs_0.3.8 ## [25] tidyselect_1.1.1 rprojroot_2.0.2 grid_4.0.4 glue_1.4.2 ## [29] R6_2.5.0 fansi_0.4.2 rmarkdown_2.6 farver_2.1.0 ## [33] purrr_0.3.4 magrittr_2.0.1 scales_1.1.1 ps_1.6.0 ## [37] htmltools_0.5.1.1 ellipsis_0.3.2 assertthat_0.2.1 colorspace_2.0-1 ## [41] labeling_0.4.2 utf8_1.2.1 stringi_1.5.3 munsell_0.5.0 ## [45] crayon_1.4.1 "
},
{
	"uri": "/git/git_cmd/git_cmd_01.html",
	"title": "Git Translation",
	"tags": ["git"],
	"description": "",
	"content": " 2021-06-22, FCA Collin\nStarting with Git from a user perspective.\nWhy should I use Git?  Back up:  If I did a mistake I can roll back to a previously working stage.  Version control:  some versions are definitely working and might be used \u0026hellip; it does not stop me to carry on the programming (e.g. I want to add a new feature, I want to correct something) and eventually update the project: all is self contained (no copy paste from a draft directory to a production one)  Collaboration:  Easy to share code. It can be a communication channel. many users can contribute simultaneously.   Where is the difficulty?  With a great power 🕸 \u0026hellip;:  Many possibilities, can be overwhelming. But: start with git branching workflow (https://git-scm.com/book/en/v2/Git-Branching-Branching-Workflows).\n  It relies on the Command Line Interface:  But: many graphical user interface, including RStudio.   Basic command Git: I want to \u0026hellip; start! Starting a git repository is simple, in the terminal git init. Where the command is invoked, it makes a .git directory which will contain the git base. However, creating a git directory is not enough, the user must decide if a file should be version controled.\nGit: I want to keep track of a new file. Using git add myfile must be understand as Git, I would like to check the evolution of the file myfile. Then for every change or stage I would like to keep track of: git commit myfile -m \u0026quot;An informative short description\u0026quot;.\nAn alternative way is to add all the files git add . and commit all git commit -am \u0026quot;Another informative commit desc..\nOf course, many IDE propose convenient graphical user interface for these operations: e.g. with RStudio, this action is done by ticking check boxes.\nGit: I don\u0026rsquo;t to track a file, never. There is this draft.R file which I don\u0026rsquo;t want to commit. To do so, I add a file .gitignore where I add the following line:\ndraft.R  I could even be more efficient and avoid every single file including the mention draft in its title, I would adapt the .gitignore file:\n*draft*  Branching Git: I want to create a draft version of the project. Git always commit modifications in a branch, the default branch is called master. The command git branch returns the list of branches:\n* master  With the command git checkout -b draft I am creating and checking out a new branch (-b named draft). All commits will be added in that branch. Looking at git branch I definitelly have two branches, the checked-out branch:\n* devel master  And I can check out the master branch again with git checkout master.\nGit, I want to merge devel in master I am satisfied with the modification I made in master, I tested it works and does not break the previous features. This modification is in the devel branch, I want to add it to the main branch. Then I need to check out the destination branch git checkout master, and merge with git merge devel. In that case, all my commits will now be part of the main branch (it has been fast forwarded, git terminology). If I want to by pass these intermediate commit and just merge the final result, I would use git merge devel --no-ff -m \u0026quot;With a message\u0026quot;.\nGit, I believe you, but I want to see the branches With git log all the commits will be visible, you can track back the full history of the work. You can define your log differently setting some optionss, e.g. git log --graph --all --decorate --oneline:\n* 5136332 (HEAD -\u0026gt; main, tag: v0.3.4, origin/main) Release |\\ | * a94f0c0 (origin/devel, devel) Addition of GSEA per WGCNA module | |\\ | | * 45fdfb1 (origin/20_gomod, 20_gomod) release | | * a58bb47 wgcna gsea go - ready | | * 42df79e per-module geneset selection | | * 5b7dd98 ongoing draft for gsea per wgcna module | | * b221a86 ongoing draft: go per module | |/ | * 668307c Up version |/ * c0b4475 minor fix * 2557230 Release version 0.3.3 |\\ | * f288328 Results of the miRNA analysis. | |\\ | | * 46fabb6 (origin/19_mirna, 19_mirna) Report review | | * 8aec514 clean | | * fc0b74a Refactoring for consistent VST normalisation | | * c16d08e mirna traits cor training | | * 5fc87aa mir: trait to gene correlation matrix, ongoing | | * c422edc Fig022 and improvement Fig008 | | * dc3f46a Fig021 miRNA volcano Training All | | * 19c9077 Fig020 mRNA volcano Training All | | * f9db6fc up version | | |\\ | |/ / |/| / | |/ | * a47a792 Up version * | 8cf34f9 (tag: v0.3.2) Delivery |\\ \\ | |/ | * 56c2f92 Production | |\\ | | * 02683e7 (18_rnaseq_res) add wgcna results | | * ace4aa1 (origin/18_rnaseq_res) export module gene in table and graph | | * 93bdaa9 Fig014 and Fig015 WGCNA Baseline | | * f11910f WGCNA cut in pieces | | * 074da27 WGCNA up scalling and modules | | * 6205e38 WGCNA object for upscaling (case A and B) | | * d0bc2e6 Prototype for trait to gene correlation matrix | | * fa4a938 Network - start with ME to traits correlations | | * efb67cc WGCNA: ind cluster and sft threshold | | * 21c09f8 Started WGCNA | | * 0f75d87 Merge branch 'main' into 18_rnaseq_res | | |\\ | |_|/ |/| | * | | e73c97e (tag: v0.3.1) Release |\\ \\ \\ | |/ / | | * 49ce03c Up-versioned  And if you want it cool: https://www.gitkraken.com/.\nCloning Git: I want to have my copy of the work. For that I need to clone the repository; the command git clone /file/path/to/the/repo, will make a copy of it in a new folder repo where the command was invoked. What is happening? Git is defining a communication channel, communication involves two parties:\n an emettor, later call the local. a receptor, later called a remote.  This new repo folder is the local, and it communicates with the remote /file/path/to/the/repo. Generally, there are two ways of communications:\n pulling: we take information from the remote (e.g. you can pull a branch) pushing: we send information to the remote (e.g. you can push a branch).  Git: I want to participate to a project Working with a copy of the work (see above), I can create a branch in my local machine. Once I did that, I should decide which branch is the starting point to contribute (we should expect devel, industry standard). Then I would create my own branch which will be synchronised with the remote location. Later, I will be able, distintly to:\n add new modification to my branch (commits) and send them to the corresponding branch in the remote: git push origin 01_mybranch.  even better:  firt time I push: git push -u origin 01_mybranch (-u for set upstream) then for the future push git push.    My branch can be used for:\n proposing new features. communicating feedback. fork the project to adapt to my own needs.  "
},
{
	"uri": "/standard/lifecycle/lcycle_01.html",
	"title": "Lifecycle",
	"tags": ["lifecycle"],
	"description": "",
	"content": "2021-03-09, FCA Collin\nPresentation of lifecycle status and shields used in production\nDocument Edition In Edit The Doc/In Edit shield indicates a section or document being currently edited. For the sake of comunication with the stakeholder, the document (or section within the document) may nonetheless have been released in spite of not having reach stability. This section/document is:\n unstable, likely to evolve. not validated: use the information within this section at your own risk. open for general overview and major comments. closed to minor comments.  Versioning Version increment is based on semver.org. It is given such as MAJOR.MINOR.PATCH; increment in:\n MAJOR version marks incompatible API changes. MINOR version adds new functionality in a backwards compatible manner. PATCH version corrects bug in a backwards-compatible fashion. (Additional numbers as extension to the MAJOR.MINOR.PATCH format are used to mark pre-release changes.)  Emojis for log    Type Title Description     ✨ feat Features A new feature   🐛 fix Bug Fixes A bug Fixi   📚 docs Documentation Documentation only changes   💎 style Styles Changes that do not affect the meaning of the     code (white-space, formatting, missing     semi-colons, etc)   📦 refact Refactoring A code change that neither fixes a bug nor     adds a feature   🚀 perf Perf. Improvt A code change that improves performance   🚨 test Tests Adding or correcting tests   🛠 build Builds Changes that affect the build system   ⚙️ ci CI Changes to our CI configuration   ♻️ chore Chores Other changes   🗑 revert Reverts Reverts a previous commit   "
},
{
	"uri": "/faq/git/git_01.html",
	"title": "Git Help",
	"tags": ["error", "warning", "debug"],
	"description": "",
	"content": "2021-03-08, FCA Collin\nCommon Problems With Git I have forgotten to start a feature branch and started modifying the devel git stash git checkout -b feat_branch git stash pop "
},
{
	"uri": "/faq/r_package/errors_01.html",
	"title": "R Pack Debug",
	"tags": ["error", "warning", "debug"],
	"description": "",
	"content": "2021-03-05, FCA Collin\nErrors and Warnings with R @export may only span a single line  Context: documenting a package with devtools::document() (ctrl+shift+d in RStudio). Problem: I am use to copy my example at the end of the function documentation, somtimes I forget to add the @examples tag. Correction: add @examples before the example.  Namespace problems Examples\nIn loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : there is no package called ‘ggplot’  Resolution:\nDelete the namespace file and generate documentation.\n"
},
{
	"uri": "/r_content/lb_01/roc_01.html",
	"title": "ROC Curves",
	"tags": ["ROC", "graph", "ggplot2"],
	"description": "",
	"content": "2021-01-11, FCA Collin (update 2021-01-12)\nPresentation The Receiver Operating Characteristic (ROC) is a general representation of a binary classifier; it accounts for:\n the sensitivity (the proportion of real positive case detected), the false positive rate (1 - sensitivity), the general performance via the area under the ROC curve (AUC).  The classifier for the example identifies tumour tissues (yes/no) in the case of lung cancer (LC) or eventually identifies the Squamous Cell Carcinoma (SCC) histological subtype. The dataset used for the graphic requires at least columns for the sensitivity, the false-positive rate and a decision rule represented by a threshold proportion, in that case varying from 0 to 1. Additionally, information about the classifier itself can include the model identification (LC, SCC), as well as the AUC (+ confidence interval estimation) as a overall evaluation of the models.\nData Lets dtaplot being as example dataset such as:\n   Threshold Sensitivity Specificity FalseAlarm ntree auc.ci auc Diag     Inf 0.0000000 1 0 10000 0.925-0.984 0.954 2) SCC   Inf 0.0000000 1 0 10000 0.938-0.989 0.964 1) LC   0.96445 0.0097087 1 0 10000 0.925-0.984 0.954 2) SCC   0.95860 0.0194175 1 0 10000 0.925-0.984 0.954 2) SCC   0.95375 0.0291262 1 0 10000 0.925-0.984 0.954 2) SCC   0.95285 0.0388350 1 0 10000 0.925-0.984 0.954 2) SCC    Some decision rules (threshold) were of interest:\n Min. error is the threshold for which the classifier overall error was at its minimum. Sens. 90%: has its better not to miss true positive patients, the threshold may be determined so as to catch 90% of true positive patient (sensibility), eventually at a cost in terms of overall error as it then automatically increase the false-alarm rate.  Lets threshold being the supplementary data characterising this two decision rules:\n`Threshold, the decision rules.    Threshold Sensitivity Specificity FalseAlarm ntree auc.ci auc Diag target Rational    0.48965 0.9368421 0.9375000 0.0625000 10000 0.938-0.989 0.964 1) LC 0.0103500 Min. error  0.49350 0.8640777 0.9813953 0.0186047 10000 0.925-0.984 0.954 2) SCC 0.0065000 Min. error  0.69835 0.9000000 0.9687500 0.0312500 10000 0.938-0.989 0.964 1) LC 0.0000000 Sens. 90%  0.35290 0.9029126 0.9441860 0.0558140 10000 0.925-0.984 0.954 2) SCC 0.0029126 Sens. 90%    Graphic The example is based on the package ggplot2, plus the optional ggthemr which provides graphical themes, for instance the themeflat.\nlibrary(ggplot2) if(require(ggthemr)) ggthemr::ggthemr(\u0026#34;flat\u0026#34;) Basic The minimal ROC representation is simply a line plot representing the sensitivity as a function of the false alarm rate, for one or the other model.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, color = Diag ) ) + geom_line( lwd = 1 ) + facet_grid( . ~ Diag ) } Aesthetic improvement Aesthetic can help improving the reading:\n the area under the curve is of interest, therefore it can be filled. the bisector delimits a model performing as good as a decision made flipping a coin (the reference model). sensibility and false-alarm rate are define from 0 to 1, the length of this two axis should equal.  { ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + theme( asp = 1 ) } Other data for more annotations The use of the model for diagnostic demands to define a threshold, various rational can be used, in the example two thresholds were defined: the minimal error, the 90% detection of positive case. Points can identify this threshold and performance on the ROC curve.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + theme( asp = 1 ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) } The plot can be further personalised manipulating the theme locally to address for instance the positioning of the legend and other settings.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) + theme( asp = 1, legend.position = \u0026#34;bottom\u0026#34;, legend.text = element_text(size = 8), legend.title = element_text(size = 8), legend.background = element_rect(fill = \u0026#34;transparent\u0026#34;), plot.background = element_rect(fill = alpha(\u0026#34;white\u0026#34;, .5), colour = \u0026#39;white\u0026#39;) ) } Final Finally, as a last piece of annotation, the AUC given with its confidence interval may help for further comparison.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) + theme( asp = 1, legend.position = \u0026#34;bottom\u0026#34;, legend.text = element_text(size = 8), legend.title = element_text(size = 8), legend.background = element_rect(fill = \u0026#34;transparent\u0026#34;), plot.background = element_rect(fill = alpha(\u0026#34;white\u0026#34;, .5), colour = \u0026#39;white\u0026#39;) ) + geom_label( data = aggregate(auc.ci ~ Diag + ntree, data = dtaplot, unique), mapping = aes(label = auc.ci, ymax = NULL, fill = NULL, color = NULL , x = .5, y = .5 ) ) } sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggthemr_1.1.0 ggplot2_3.3.3 ## ## loaded via a namespace (and not attached): ## [1] pillar_1.5.1 compiler_4.0.4 highr_0.8 tools_4.0.4 ## [5] digest_0.6.27 evaluate_0.14 lifecycle_1.0.0 tibble_3.1.0 ## [9] gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.10 DBI_1.1.1 ## [13] yaml_2.2.1 xfun_0.22 withr_2.4.1 stringr_1.4.0 ## [17] dplyr_1.0.5 knitr_1.31 generics_0.1.0 vctrs_0.3.7 ## [21] grid_4.0.4 tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 ## [25] fansi_0.4.2 rmarkdown_2.6 farver_2.1.0 purrr_0.3.4 ## [29] magrittr_2.0.1 scales_1.1.1 ellipsis_0.3.1 htmltools_0.5.1.1 ## [33] assertthat_0.2.1 colorspace_2.0-0 labeling_0.4.2 utf8_1.2.1 ## [37] stringi_1.5.3 munsell_0.5.0 crayon_1.4.1 "
},
{
	"uri": "/r_content/roc_01/roc_01.html",
	"title": "ROC Curves",
	"tags": ["ROC", "graph", "ggplot2"],
	"description": "",
	"content": "2021-01-11, FCA Collin (update 2021-01-12)\nPresentation The Receiver Operating Characteristic (ROC) is a general representation of a binary classifier; it accounts for:\n the sensitivity (the proportion of real positive case detected), the false positive rate (1 - sensitivity), the general performance via the area under the ROC curve (AUC).  The classifier for the example identifies tumour tissues (yes/no) in the case of lung cancer (LC) or eventually identifies the Squamous Cell Carcinoma (SCC) histological subtype. The dataset used for the graphic requires at least columns for the sensitivity, the false-positive rate and a decision rule represented by a threshold proportion, in that case varying from 0 to 1. Additionally, information about the classifier itself can include the model identification (LC, SCC), as well as the AUC (+ confidence interval estimation) as a overall evaluation of the models.\nData Lets dtaplot being as example dataset such as:\n   Threshold Sensitivity Specificity FalseAlarm ntree auc.ci auc Diag     Inf 0.0000000 1 0 10000 0.925-0.984 0.954 2) SCC   Inf 0.0000000 1 0 10000 0.938-0.989 0.964 1) LC   0.96445 0.0097087 1 0 10000 0.925-0.984 0.954 2) SCC   0.95860 0.0194175 1 0 10000 0.925-0.984 0.954 2) SCC   0.95375 0.0291262 1 0 10000 0.925-0.984 0.954 2) SCC   0.95285 0.0388350 1 0 10000 0.925-0.984 0.954 2) SCC    Some decision rules (threshold) were of interest:\n Min. error is the threshold for which the classifier overall error was at its minimum. Sens. 90%: has its better not to miss true positive patients, the threshold may be determined so as to catch 90% of true positive patient (sensibility), eventually at a cost in terms of overall error as it then automatically increase the false-alarm rate.  Lets threshold being the supplementary data characterising this two decision rules:\n`Threshold, the decision rules.    Threshold Sensitivity Specificity FalseAlarm ntree auc.ci auc Diag target Rational    0.48965 0.9368421 0.9375000 0.0625000 10000 0.938-0.989 0.964 1) LC 0.0103500 Min. error  0.49350 0.8640777 0.9813953 0.0186047 10000 0.925-0.984 0.954 2) SCC 0.0065000 Min. error  0.69835 0.9000000 0.9687500 0.0312500 10000 0.938-0.989 0.964 1) LC 0.0000000 Sens. 90%  0.35290 0.9029126 0.9441860 0.0558140 10000 0.925-0.984 0.954 2) SCC 0.0029126 Sens. 90%    Graphic The example is based on the package ggplot2, plus the optional ggthemr which provides graphical themes, for instance the themeflat.\nlibrary(ggplot2) if(require(ggthemr)) ggthemr::ggthemr(\u0026#34;flat\u0026#34;) Basic The minimal ROC representation is simply a line plot representing the sensitivity as a function of the false alarm rate, for one or the other model.\nggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, color = Diag ) ) + geom_line( lwd = 1 ) + facet_grid( . ~ Diag ) Aesthetic improvement Aesthetic can help improving the reading:\n the area under the curve is of interest, therefore it can be filled. the bisector delimits a model performing as good as a decision made flipping a coin (the reference model). sensibility and false-alarm rate are define from 0 to 1, the length of this two axis should equal.  { ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + theme( asp = 1 ) } Other data for more annotations The use of the model for diagnostic demands to define a threshold, various rational can be used, in the example two thresholds were defined: the minimal error, the 90% detection of positive case. Points can identify this threshold and performance on the ROC curve.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + theme( asp = 1 ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) } The plot can be further personalised manipulating the theme locally to address for instance the positioning of the legend and other settings.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) + theme( asp = 1, legend.position = \u0026#34;bottom\u0026#34;, legend.text = element_text(size = 8), legend.title = element_text(size = 8), legend.background = element_rect(fill = \u0026#34;transparent\u0026#34;), plot.background = element_rect(fill = alpha(\u0026#34;white\u0026#34;, .5), colour = \u0026#39;white\u0026#39;) ) } Final Finally, as a last piece of annotation, the AUC given with its confidence interval may help for further comparison.\n{ ggplot( data = dtaplot, mapping = aes( x = FalseAlarm, y = Sensitivity, ymax = Sensitivity, fill = Diag, color = Diag ) ) + geom_ribbon( ymin = 0, alpha = .5, color = NA ) + geom_line( lwd = 1 ) + geom_abline( slope = 1, intercept = 0, col = \u0026#34;gray50\u0026#34;, lwd = 2, lty = 2 ) + xlab( \u0026#34;False Alarm Rate (1 - specificity)\u0026#34; ) + facet_grid( . ~ Diag ) + geom_point( data = threshold, mapping = aes(shape = Rational, colour = Rational), size = 3 ) + theme( asp = 1, legend.position = \u0026#34;bottom\u0026#34;, legend.text = element_text(size = 8), legend.title = element_text(size = 8), legend.background = element_rect(fill = \u0026#34;transparent\u0026#34;), plot.background = element_rect(fill = alpha(\u0026#34;white\u0026#34;, .5), colour = \u0026#39;white\u0026#39;) ) + geom_label( data = aggregate(auc.ci ~ Diag + ntree, data = dtaplot, unique), mapping = aes(label = auc.ci, ymax = NULL, fill = NULL, color = NULL , x = .5, y = .5 ) ) } sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/libopenblasp-r0.3.5.so ## ## locale: ## [1] LC_CTYPE=en_GB.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_GB.UTF-8 LC_COLLATE=en_GB.UTF-8 ## [5] LC_MONETARY=en_GB.UTF-8 LC_MESSAGES=en_GB.UTF-8 ## [7] LC_PAPER=en_GB.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggthemr_1.1.0 ggplot2_3.3.3 ## ## loaded via a namespace (and not attached): ## [1] pillar_1.5.1 compiler_4.0.4 highr_0.8 tools_4.0.4 ## [5] digest_0.6.27 evaluate_0.14 lifecycle_1.0.0 tibble_3.1.0 ## [9] gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.10 DBI_1.1.1 ## [13] yaml_2.2.1 xfun_0.22 withr_2.4.1 stringr_1.4.0 ## [17] dplyr_1.0.5 knitr_1.31 generics_0.1.0 vctrs_0.3.7 ## [21] grid_4.0.4 tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 ## [25] fansi_0.4.2 rmarkdown_2.6 farver_2.1.0 purrr_0.3.4 ## [29] magrittr_2.0.1 scales_1.1.1 ellipsis_0.3.1 htmltools_0.5.1.1 ## [33] assertthat_0.2.1 colorspace_2.0-0 labeling_0.4.2 utf8_1.2.1 ## [37] stringi_1.5.3 munsell_0.5.0 crayon_1.4.1 "
},
{
	"uri": "/r_content/btc.html",
	"title": "Beat The Code",
	"tags": [],
	"description": "",
	"content": "In content/r_content/, R outputs are organised in folder, a folder corresponds to an item in the navigation menu.\n"
},
{
	"uri": "/git.html",
	"title": "Git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/r_content.html",
	"title": "R",
	"tags": [],
	"description": "",
	"content": "In content/r_content/, R outputs are organised in folder, a folder corresponds to an item in the navigation menu.\n"
},
{
	"uri": "/standard.html",
	"title": "Standard",
	"tags": [],
	"description": "",
	"content": "Standard and information.\n"
},
{
	"uri": "/r_content/utils.html",
	"title": "Utils",
	"tags": [],
	"description": "",
	"content": "In content/r_content/, R outputs are organised in folder, a folder corresponds to an item in the navigation menu.\n"
},
{
	"uri": "/faq.html",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": "I regularly encounter some errors, it may be time to keep track of them and propose standard resolutions.\n"
},
{
	"uri": "/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/date.html",
	"title": "Date",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/standard/date.html",
	"title": "Date and Time",
	"tags": ["date", "time"],
	"description": "",
	"content": "2021-08-T05:49+0000, FCA Collin\nStandard followed to referred to date and time\nDate and time follows ISO 8601-1:2019, \u0026ldquo;Date and time - Representations for information interchange - Part 1: Basic rules\u0026rdquo;.\nWith R:\n# Date format(Sys.time(), \u0026#34;%Y-%m\u0026#34;) #\u0026gt; [1] \u0026#34;2021-08\u0026#34; format(Sys.time(), \u0026#34;%Y-%m-%d\u0026#34;) #\u0026gt; [1] \u0026#34;2021-08-10\u0026#34; # Date (compact) format(Sys.time(), \u0026#34;%Y%m\u0026#34;) #\u0026gt; [1] \u0026#34;202108\u0026#34; format(Sys.time(), \u0026#34;%Y%m%d\u0026#34;) #\u0026gt; [1] \u0026#34;20210810\u0026#34; # + Time format(Sys.time(), \u0026#34;%Y-%m-%dT%R%z\u0026#34;) #\u0026gt; [1] \u0026#34;2021-08-10T06:03+0000\u0026#34; format(Sys.time(), \u0026#34;%Y%m%dT%R%z\u0026#34;) #\u0026gt; [1] \u0026#34;20210810T06:03+0000\u0026#34; format(Sys.time(), \u0026#34;%Y-%m-%dT%T%z\u0026#34;) #\u0026gt; [1] \u0026#34;2021-08-10T06:03:19+0000\u0026#34; format(Sys.time(), \u0026#34;%Y%m%dT%T%z\u0026#34;) #\u0026gt; [1] \u0026#34;20210810T06:03:19+0000\u0026#34; Created on 2021-08-10 by the reprex package (v2.0.0)\nSome side advantages:\n alphabetic order matches chronological order (convenient for ordering) unambiguous and largely adopted across the world. "
},
{
	"uri": "/tags/debug.html",
	"title": "Debug",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/error.html",
	"title": "Error",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/ggplot2.html",
	"title": "Ggplot2",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/git.html",
	"title": "Git",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/graph.html",
	"title": "Graph",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/guide.html",
	"title": "Guide",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/",
	"title": "Guide",
	"tags": ["hugo", "guide"],
	"description": "",
	"content": " Welcome 2021-03-10, FCA Collin\nThis guide contains information for stakeholders about methods used in when I develop programs. This is still a fairly new initiative and is likely to strongly evolve in the coming months.\nUnder The Hood This is an example of static web page generated with Hugo. No big knowledge of html, Hugo comes with ready-to-use features, further augmented by themes . For instance, the learn theme used for these pages has nice features for project documentation, included but not restricted to:\n keyword search box in the top-left corner. content folder structure corresponding to the left expandable navigation menu. the code is highlighted.  Try the search box in the top-left corner and look for ggplot2.\n Different themes serve different purpose, I have found the Creative portfolio especially useful to present my \u0026hellip; portfolio!\nGitHub repository, check directory hugo.\nThe user simply edits the content folder with markdown files, adds figures, docs, or other elements in the static folder and run the commandhugoto render the webpage in thepublic` folder. Nicely, with the following comment the website is dynamically rendered at http://localhost:1313/ and modifications of the source are automatically rendered.\nhugo server  Credits  Hugo-theme-learn is a theme for Hugo, a fast and modern static website engine written in Go.  "
},
{
	"uri": "/tags/hugo.html",
	"title": "Hugo",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/lifecycle.html",
	"title": "Lifecycle",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/roc.html",
	"title": "Roc",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/time.html",
	"title": "Time",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tags/warning.html",
	"title": "Warning",
	"tags": [],
	"description": "",
	"content": ""
}]